{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import qr\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def sketch_matrix(m, n_columns, non_zero_entries):\n",
    "    #matrix with all zero entries\n",
    "    S = np.zeros((m, n_columns))\n",
    "    scaling_factor = 1 / np.sqrt(non_zero_entries)\n",
    "    #loop through each columns to edit the non zero entries in\n",
    "    for col in range(n_columns):\n",
    "        # Randomly select position of non_zero entries\n",
    "        nz_positions = np.random.choice(m, non_zero_entries, replace=False)\n",
    "        \n",
    "        # Randomly assign values of either 1 or -1 to these positions\n",
    "        values = np.random.choice([1, -1], non_zero_entries)* scaling_factor\n",
    "        \n",
    "        # Assign the values to the selected positions in the column\n",
    "        for idx, value in zip(nz_positions, values):\n",
    "            S[idx, col] = value\n",
    "    \n",
    "    return S\n",
    "\n",
    "#Higher leverage scores indicate more influential data points.\n",
    "def estimate_leverage_scores(A, R, gamma):\n",
    "    \"\"\"Estimate leverage scores ˜li for each row using matrix R (similar to Lemma 5.1).\"\"\"\n",
    "    n, d = A.shape\n",
    "    k = int(np.ceil(d / gamma))  # Choose k based on γ\n",
    "    G = np.random.randn(d, k) / np.sqrt(k) #scale the matrix\n",
    "    \n",
    "    # Compute the leverage scores ˜li = || e_i^T AR G ||_2^2\n",
    "    ARG = A @ (R @ G)\n",
    "    leverage_scores = np.sum(ARG ** 2, axis=1)  # || e_i^T AR G ||_2^2\n",
    "    \n",
    "    return leverage_scores\n",
    "\n",
    "def fast_least_squares_sgd(A, b, non_zero_entries,T=100, eta=0.001, gamma=0.1, batch_size=10):\n",
    "    \"\"\"\n",
    "    Fast least squares via preconditioned mini-batch SGD using sketch matrix and leverage scores.\n",
    "    \n",
    "    Parameters:\n",
    "    - A: (n, d) NumPy array (or sparse matrix), the design matrix.\n",
    "    - b: (n,) NumPy array, the target vector.\n",
    "    - T: Number of SGD iterations.\n",
    "    - eta: Learning rate.\n",
    "    - gamma: Approximation parameter for leverage score estimation.\n",
    "    - batch_size: Number of rows sampled per SGD iteration.\n",
    "    \n",
    "    Returns:\n",
    "    - x: (d,) NumPy array, the estimated least squares solution.\n",
    "    \"\"\"\n",
    "    n, d = A.shape\n",
    "    m = min(2 * d, n)  # Typically 2d rows for sketch matrix\n",
    "    \n",
    "    # Step 1: Generate the sketch matrix S using the sketch_matrix function\n",
    "    S = sketch_matrix(m, n, non_zero_entries)\n",
    "\n",
    "    # Step 2: Compute SA and Sb\n",
    "    SA = S @ A\n",
    "    Sb = S @ b\n",
    "\n",
    "    # Step 3: Compute QR decomposition of SA\n",
    "    Q, R_inv = np.linalg.qr(SA)\n",
    "    R = np.linalg.inv(R_inv)\n",
    "\n",
    "    # Step 4: Compute leverage score estimates\n",
    "    leverage_scores = estimate_leverage_scores(A, R, gamma)\n",
    "    leverage_probs = leverage_scores / np.sum(leverage_scores)  # Normalize\n",
    "\n",
    "    # Step 5: Compute initial x0 by solving (SAx = Sb)\n",
    "    x = np.linalg.lstsq(SA, Sb, rcond=None)[0]\n",
    "\n",
    "    # Step 6: Perform mini-batch SGD\n",
    "    for t in range(T):\n",
    "        # Step 6.1: Sample batch indices based on leverage scores\n",
    "        batch_indices = np.random.choice(n, size=batch_size, p=leverage_probs)\n",
    "        \n",
    "        # Step 6.2: Construct StA and Stb for mini-batch\n",
    "        StA = A[batch_indices]\n",
    "        Stb = b[batch_indices]\n",
    "\n",
    "        # Step 6.3: Compute gradient of the least squares loss\n",
    "        gt = 2 * StA.T @ (StA @ x - Stb)\n",
    "\n",
    "        # Step 6.4: Update x using preconditioned gradient\n",
    "        x = x - eta * R @ (R.T @ gt)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0., -1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketch_matrix(5,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = 10000, 100 \n",
    "non_zero_entries = 10\n",
    "A = np.random.randn(n, d)  # Design matrix A\n",
    "x_true = np.random.randn(d)  # True solution vector x\n",
    "b = A @ x_true + np.random.randn(n) * 0.1\n",
    "\n",
    "\n",
    "# Estimate the solution using the algorithm\n",
    "x_estimated = fast_least_squares_sgd(A, b, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011161879635956588"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean((x_estimated - x_true) ** 2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0946171174895882e-06"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve least squares using NumPy's lstsq (normal OLS solution)\n",
    "x_ols = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "\n",
    "# Calculate the MSE for OLS\n",
    "mse_ols = np.mean((x_ols - x_true) ** 2)\n",
    "mse_ols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
